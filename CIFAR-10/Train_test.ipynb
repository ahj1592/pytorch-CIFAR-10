{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Train-test.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "13c1704cce0b41d8ac73f87df7073645": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_94fa999916254fbb980b509c736752d2",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_c17f0764d7ee40498e80f47b3d138864",
              "IPY_MODEL_5c415be6ac9143ddb2c6ad58a11d86e2",
              "IPY_MODEL_53c9deaf961c4a359aaa37137dbbc37a"
            ]
          }
        },
        "94fa999916254fbb980b509c736752d2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "c17f0764d7ee40498e80f47b3d138864": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_f824dce72d6246eaaf744084bd5f6d15",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_c276755cbca3480ab6c6a1a5ef9a4c72"
          }
        },
        "5c415be6ac9143ddb2c6ad58a11d86e2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_b96eeec0a44549149f7afeec6915d0ff",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 170498071,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 170498071,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_f7929088b1d7477f959614b5b29a71a2"
          }
        },
        "53c9deaf961c4a359aaa37137dbbc37a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_b96579d8dbf947118799c727dcb2563f",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 170499072/? [00:02&lt;00:00, 74143620.86it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_dd1a29f0f8524e5b8a908513b8ef386a"
          }
        },
        "f824dce72d6246eaaf744084bd5f6d15": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "c276755cbca3480ab6c6a1a5ef9a4c72": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "b96eeec0a44549149f7afeec6915d0ff": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "f7929088b1d7477f959614b5b29a71a2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "b96579d8dbf947118799c727dcb2563f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "dd1a29f0f8524e5b8a908513b8ef386a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Acplf83oEsiV"
      },
      "source": [
        "# Check the device"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b1yS7yRCEOzF",
        "outputId": "6ef8422d-dcc8-4e29-d20d-8c3477ad92a4"
      },
      "source": [
        "import torch\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(device)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cpu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gH1f5wA3FSqc"
      },
      "source": [
        "# Download CIFAR-10 and build dataloader"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 82,
          "referenced_widgets": [
            "13c1704cce0b41d8ac73f87df7073645",
            "94fa999916254fbb980b509c736752d2",
            "c17f0764d7ee40498e80f47b3d138864",
            "5c415be6ac9143ddb2c6ad58a11d86e2",
            "53c9deaf961c4a359aaa37137dbbc37a",
            "f824dce72d6246eaaf744084bd5f6d15",
            "c276755cbca3480ab6c6a1a5ef9a4c72",
            "b96eeec0a44549149f7afeec6915d0ff",
            "f7929088b1d7477f959614b5b29a71a2",
            "b96579d8dbf947118799c727dcb2563f",
            "dd1a29f0f8524e5b8a908513b8ef386a"
          ]
        },
        "id": "zbKycdjaErH7",
        "outputId": "e839b93d-4468-4c1a-9abd-e998a71d6a95"
      },
      "source": [
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "train_data = torchvision.datasets.CIFAR10(root='./datasets',\n",
        "                                        train=True,\n",
        "                                        transform=transforms.ToTensor(),\n",
        "                                        download=True)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./datasets/cifar-10-python.tar.gz\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "13c1704cce0b41d8ac73f87df7073645",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "  0%|          | 0/170498071 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./datasets/cifar-10-python.tar.gz to ./datasets\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5ZnLg2YxFKjG",
        "outputId": "54491a7f-d03b-4088-c6ec-e6a906125424"
      },
      "source": [
        "len(train_data)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "50000"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wtFUqWuaEu8Z"
      },
      "source": [
        "BATCH_SIZE = 20\n",
        "train_loader = torch.utils.data.DataLoader(dataset=train_data,\n",
        "                                           batch_size=BATCH_SIZE,\n",
        "                                           shuffle=True)"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Yd3zOBsSIxsm",
        "outputId": "0f437599-b93d-47a0-d106-b2c82ae07628"
      },
      "source": [
        "image, label = next(iter(train_loader))\n",
        "print(image.shape)\n",
        "print(image.shape[-1])\n",
        "print(len(train_loader))"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([20, 3, 32, 32])\n",
            "32\n",
            "2500\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U37e2mcCFbUz"
      },
      "source": [
        "# Define CNN model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CpMapsgtFPJA"
      },
      "source": [
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torchsummary as summary"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ft1kLjeTFgha"
      },
      "source": [
        "class CNN(nn.Module):\n",
        "  def __init__(self, in_channel, n_classes=10):\n",
        "    super(CNN, self).__init__()\n",
        "    self.layer1 = nn.Sequential(\n",
        "        nn.Conv2d(in_channel, 6, 5, stride=1, padding=2),\n",
        "        nn.BatchNorm2d(6),\n",
        "        nn.ReLU(),\n",
        "        nn.MaxPool2d(2, 2)\n",
        "        # (32, 32) -> (16, 16)\n",
        "    )\n",
        "    self.layer2 = nn.Sequential(\n",
        "        nn.Conv2d(6, 16, 3, stride=1, padding=1),\n",
        "        nn.BatchNorm2d(16),\n",
        "        nn.ReLU(),\n",
        "        nn.MaxPool2d(2, 2)\n",
        "        # (16, 16) -> (8, 8)\n",
        "    )\n",
        "    self.layer3 = nn.Sequential(\n",
        "        nn.Conv2d(16, 32, 3, stride=1, padding=1),\n",
        "        nn.BatchNorm2d(32),\n",
        "        nn.ReLU(),\n",
        "        nn.MaxPool2d(2, 2)\n",
        "        # (8, 8) -> (4, 4)\n",
        "    )\n",
        "    self.layer4 = nn.Linear(4*4*32, 120)\n",
        "    self.layer5 = nn.Linear(120, 84)\n",
        "    self.fc = nn.Linear(84, n_classes)\n",
        "\n",
        "  def forward(self, x):\n",
        "    x = self.layer1(x)\n",
        "    x = self.layer2(x)\n",
        "    x = self.layer3(x)\n",
        "    x = x.reshape(x.size(0),-1)\n",
        "    x = F.relu(self.layer4(x))\n",
        "    x = F.relu(self.layer5(x))\n",
        "    x = F.softmax(self.fc(x))\n",
        "    return x"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_x8ecNqqKYRZ"
      },
      "source": [
        "import os, sys\n",
        "import numpy as np\n",
        "import random\n",
        "\n",
        "def fix_seeds(seed = 42, use_torch=False):\n",
        "    # fix the seed for reproducibility \n",
        "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
        "    random.seed(seed)\n",
        "    np.random.seed(seed)\n",
        "\n",
        "    if use_torch: \n",
        "        torch.manual_seed(seed) \n",
        "        torch.cuda.manual_seed(seed)\n",
        "        torch.backends.cudnn.deterministic = True"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AuHI_CQgJ0sW"
      },
      "source": [
        "def show_model_summary(model):\n",
        "    print('{:=^60}'.format(\"=\"))\n",
        "    print('{:^60}'.format(\"model summary\"))\n",
        "    print('{:=^60}'.format(\"=\"))\n",
        "    for param_tensor in model.state_dict():\n",
        "        print('%-30s'%param_tensor, '{:^30}'.format(str(model.state_dict()[param_tensor].size())))\n",
        "    print('{:=^60}'.format(\"=\"))"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7pBQHt85KU7V"
      },
      "source": [
        "def init_weights(m):\n",
        "    # initialize the weight, bias\n",
        "    if isinstance(m, nn.Conv2d):\n",
        "        torch.nn.init.kaiming_uniform_(m.weight.data)\n",
        "        if m.bias is not None:\n",
        "            torch.nn.init.normal_(m.bias.data)\n",
        "    elif isinstance(m, nn.BatchNorm2d):\n",
        "        torch.nn.init.normal_(m.weight.data, mean=1, std=0.02)\n",
        "        torch.nn.init.constant_(m.bias.data, 0)\n",
        "    elif isinstance(m, nn.Linear):\n",
        "        torch.nn.init.kaiming_uniform_(m.weight.data)\n",
        "        torch.nn.init.normal_(m.bias.data)"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FrHe-AzstR79"
      },
      "source": [
        "# train the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q38bRC5cLOwl",
        "outputId": "7585b165-8a16-4745-efbf-4247ee590029"
      },
      "source": [
        "model = CNN(in_channel=image.shape[1], n_classes=10).to(device)\n",
        "\n",
        "fix_seeds(seed=42, use_torch=True)\n",
        "# weight initialize\n",
        "model.apply(init_weights)\n",
        "\n",
        "show_model_summary(model)\n",
        "\n",
        "learning_rate = 1e-4\n",
        "EPOCHS = 100\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
        "\n",
        "model.train()\n",
        "steps = len(train_loader)\n",
        "train_loss = []\n",
        "\n",
        "for epoch in range(1, EPOCHS + 1):\n",
        "    total_loss, cnt = 0, 0\n",
        "    for i, (image, label) in enumerate(train_loader, 1):\n",
        "        image = image.to(device)\n",
        "        label = label.to(device)\n",
        "\n",
        "        output = model(image)\n",
        "        loss = criterion(output, label)\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        train_loss.append(loss)\n",
        "        total_loss += loss.item()\n",
        "        cnt += 1\n",
        "\n",
        "        if i % (steps / 5) == 0:\n",
        "            avg_loss = total_loss / cnt\n",
        "            print(f'Epoch: [{epoch}/{EPOCHS}], Batch steps: [{i}|{steps}] Average Loss: {avg_loss:.4f}')\n",
        "            total_loss, cnt = 0, 0\n",
        "    print()"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============================================================\n",
            "                       model summary                        \n",
            "============================================================\n",
            "layer1.0.weight                   torch.Size([6, 3, 5, 5])   \n",
            "layer1.0.bias                         torch.Size([6])        \n",
            "layer1.1.weight                       torch.Size([6])        \n",
            "layer1.1.bias                         torch.Size([6])        \n",
            "layer1.1.running_mean                 torch.Size([6])        \n",
            "layer1.1.running_var                  torch.Size([6])        \n",
            "layer1.1.num_batches_tracked           torch.Size([])        \n",
            "layer2.0.weight                  torch.Size([16, 6, 3, 3])   \n",
            "layer2.0.bias                         torch.Size([16])       \n",
            "layer2.1.weight                       torch.Size([16])       \n",
            "layer2.1.bias                         torch.Size([16])       \n",
            "layer2.1.running_mean                 torch.Size([16])       \n",
            "layer2.1.running_var                  torch.Size([16])       \n",
            "layer2.1.num_batches_tracked           torch.Size([])        \n",
            "layer3.0.weight                  torch.Size([32, 16, 3, 3])  \n",
            "layer3.0.bias                         torch.Size([32])       \n",
            "layer3.1.weight                       torch.Size([32])       \n",
            "layer3.1.bias                         torch.Size([32])       \n",
            "layer3.1.running_mean                 torch.Size([32])       \n",
            "layer3.1.running_var                  torch.Size([32])       \n",
            "layer3.1.num_batches_tracked           torch.Size([])        \n",
            "layer4.weight                      torch.Size([120, 512])    \n",
            "layer4.bias                          torch.Size([120])       \n",
            "layer5.weight                      torch.Size([84, 120])     \n",
            "layer5.bias                           torch.Size([84])       \n",
            "fc.weight                           torch.Size([10, 84])     \n",
            "fc.bias                               torch.Size([10])       \n",
            "============================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:36: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: [1/100], Batch steps: [500|2500] Average Loss: 2.2323\n",
            "Epoch: [1/100], Batch steps: [1000|2500] Average Loss: 2.1647\n",
            "Epoch: [1/100], Batch steps: [1500|2500] Average Loss: 2.1155\n",
            "Epoch: [1/100], Batch steps: [2000|2500] Average Loss: 2.0817\n",
            "Epoch: [1/100], Batch steps: [2500|2500] Average Loss: 2.0649\n",
            "\n",
            "Epoch: [2/100], Batch steps: [500|2500] Average Loss: 2.0523\n",
            "Epoch: [2/100], Batch steps: [1000|2500] Average Loss: 2.0414\n",
            "Epoch: [2/100], Batch steps: [1500|2500] Average Loss: 2.0378\n",
            "Epoch: [2/100], Batch steps: [2000|2500] Average Loss: 2.0245\n",
            "Epoch: [2/100], Batch steps: [2500|2500] Average Loss: 2.0316\n",
            "\n",
            "Epoch: [3/100], Batch steps: [500|2500] Average Loss: 2.0121\n",
            "Epoch: [3/100], Batch steps: [1000|2500] Average Loss: 2.0145\n",
            "Epoch: [3/100], Batch steps: [1500|2500] Average Loss: 2.0068\n",
            "Epoch: [3/100], Batch steps: [2000|2500] Average Loss: 2.0028\n",
            "Epoch: [3/100], Batch steps: [2500|2500] Average Loss: 1.9998\n",
            "\n",
            "Epoch: [4/100], Batch steps: [500|2500] Average Loss: 1.9836\n",
            "Epoch: [4/100], Batch steps: [1000|2500] Average Loss: 1.9965\n",
            "Epoch: [4/100], Batch steps: [1500|2500] Average Loss: 1.9884\n",
            "Epoch: [4/100], Batch steps: [2000|2500] Average Loss: 1.9893\n",
            "Epoch: [4/100], Batch steps: [2500|2500] Average Loss: 1.9800\n",
            "\n",
            "Epoch: [5/100], Batch steps: [500|2500] Average Loss: 1.9714\n",
            "Epoch: [5/100], Batch steps: [1000|2500] Average Loss: 1.9755\n",
            "Epoch: [5/100], Batch steps: [1500|2500] Average Loss: 1.9697\n",
            "Epoch: [5/100], Batch steps: [2000|2500] Average Loss: 1.9723\n",
            "Epoch: [5/100], Batch steps: [2500|2500] Average Loss: 1.9780\n",
            "\n",
            "Epoch: [6/100], Batch steps: [500|2500] Average Loss: 1.9616\n",
            "Epoch: [6/100], Batch steps: [1000|2500] Average Loss: 1.9560\n",
            "Epoch: [6/100], Batch steps: [1500|2500] Average Loss: 1.9683\n",
            "Epoch: [6/100], Batch steps: [2000|2500] Average Loss: 1.9597\n",
            "Epoch: [6/100], Batch steps: [2500|2500] Average Loss: 1.9448\n",
            "\n",
            "Epoch: [7/100], Batch steps: [500|2500] Average Loss: 1.9251\n",
            "Epoch: [7/100], Batch steps: [1000|2500] Average Loss: 1.9253\n",
            "Epoch: [7/100], Batch steps: [1500|2500] Average Loss: 1.9226\n",
            "Epoch: [7/100], Batch steps: [2000|2500] Average Loss: 1.9174\n",
            "Epoch: [7/100], Batch steps: [2500|2500] Average Loss: 1.9179\n",
            "\n",
            "Epoch: [8/100], Batch steps: [500|2500] Average Loss: 1.9015\n",
            "Epoch: [8/100], Batch steps: [1000|2500] Average Loss: 1.9001\n",
            "Epoch: [8/100], Batch steps: [1500|2500] Average Loss: 1.9108\n",
            "Epoch: [8/100], Batch steps: [2000|2500] Average Loss: 1.9069\n",
            "Epoch: [8/100], Batch steps: [2500|2500] Average Loss: 1.9034\n",
            "\n",
            "Epoch: [9/100], Batch steps: [500|2500] Average Loss: 1.8981\n",
            "Epoch: [9/100], Batch steps: [1000|2500] Average Loss: 1.8923\n",
            "Epoch: [9/100], Batch steps: [1500|2500] Average Loss: 1.8927\n",
            "Epoch: [9/100], Batch steps: [2000|2500] Average Loss: 1.8926\n",
            "Epoch: [9/100], Batch steps: [2500|2500] Average Loss: 1.8920\n",
            "\n",
            "Epoch: [10/100], Batch steps: [500|2500] Average Loss: 1.8897\n",
            "Epoch: [10/100], Batch steps: [1000|2500] Average Loss: 1.8859\n",
            "Epoch: [10/100], Batch steps: [1500|2500] Average Loss: 1.8845\n",
            "Epoch: [10/100], Batch steps: [2000|2500] Average Loss: 1.8785\n",
            "Epoch: [10/100], Batch steps: [2500|2500] Average Loss: 1.8826\n",
            "\n",
            "Epoch: [11/100], Batch steps: [500|2500] Average Loss: 1.8732\n",
            "Epoch: [11/100], Batch steps: [1000|2500] Average Loss: 1.8708\n",
            "Epoch: [11/100], Batch steps: [1500|2500] Average Loss: 1.8739\n",
            "Epoch: [11/100], Batch steps: [2000|2500] Average Loss: 1.8808\n",
            "Epoch: [11/100], Batch steps: [2500|2500] Average Loss: 1.8808\n",
            "\n",
            "Epoch: [12/100], Batch steps: [500|2500] Average Loss: 1.8740\n",
            "Epoch: [12/100], Batch steps: [1000|2500] Average Loss: 1.8644\n",
            "Epoch: [12/100], Batch steps: [1500|2500] Average Loss: 1.8650\n",
            "Epoch: [12/100], Batch steps: [2000|2500] Average Loss: 1.8702\n",
            "Epoch: [12/100], Batch steps: [2500|2500] Average Loss: 1.8651\n",
            "\n",
            "Epoch: [13/100], Batch steps: [500|2500] Average Loss: 1.8606\n",
            "Epoch: [13/100], Batch steps: [1000|2500] Average Loss: 1.8613\n",
            "Epoch: [13/100], Batch steps: [1500|2500] Average Loss: 1.8645\n",
            "Epoch: [13/100], Batch steps: [2000|2500] Average Loss: 1.8625\n",
            "Epoch: [13/100], Batch steps: [2500|2500] Average Loss: 1.8577\n",
            "\n",
            "Epoch: [14/100], Batch steps: [500|2500] Average Loss: 1.8486\n",
            "Epoch: [14/100], Batch steps: [1000|2500] Average Loss: 1.8495\n",
            "Epoch: [14/100], Batch steps: [1500|2500] Average Loss: 1.8582\n",
            "Epoch: [14/100], Batch steps: [2000|2500] Average Loss: 1.8567\n",
            "Epoch: [14/100], Batch steps: [2500|2500] Average Loss: 1.8515\n",
            "\n",
            "Epoch: [15/100], Batch steps: [500|2500] Average Loss: 1.8518\n",
            "Epoch: [15/100], Batch steps: [1000|2500] Average Loss: 1.8533\n",
            "Epoch: [15/100], Batch steps: [1500|2500] Average Loss: 1.8436\n",
            "Epoch: [15/100], Batch steps: [2000|2500] Average Loss: 1.8414\n",
            "Epoch: [15/100], Batch steps: [2500|2500] Average Loss: 1.8468\n",
            "\n",
            "Epoch: [16/100], Batch steps: [500|2500] Average Loss: 1.8373\n",
            "Epoch: [16/100], Batch steps: [1000|2500] Average Loss: 1.8431\n",
            "Epoch: [16/100], Batch steps: [1500|2500] Average Loss: 1.8436\n",
            "Epoch: [16/100], Batch steps: [2000|2500] Average Loss: 1.8401\n",
            "Epoch: [16/100], Batch steps: [2500|2500] Average Loss: 1.8456\n",
            "\n",
            "Epoch: [17/100], Batch steps: [500|2500] Average Loss: 1.8369\n",
            "Epoch: [17/100], Batch steps: [1000|2500] Average Loss: 1.8371\n",
            "Epoch: [17/100], Batch steps: [1500|2500] Average Loss: 1.8387\n",
            "Epoch: [17/100], Batch steps: [2000|2500] Average Loss: 1.8309\n",
            "Epoch: [17/100], Batch steps: [2500|2500] Average Loss: 1.8379\n",
            "\n",
            "Epoch: [18/100], Batch steps: [500|2500] Average Loss: 1.8360\n",
            "Epoch: [18/100], Batch steps: [1000|2500] Average Loss: 1.8311\n",
            "Epoch: [18/100], Batch steps: [1500|2500] Average Loss: 1.8295\n",
            "Epoch: [18/100], Batch steps: [2000|2500] Average Loss: 1.8350\n",
            "Epoch: [18/100], Batch steps: [2500|2500] Average Loss: 1.8245\n",
            "\n",
            "Epoch: [19/100], Batch steps: [500|2500] Average Loss: 1.8271\n",
            "Epoch: [19/100], Batch steps: [1000|2500] Average Loss: 1.8288\n",
            "Epoch: [19/100], Batch steps: [1500|2500] Average Loss: 1.8249\n",
            "Epoch: [19/100], Batch steps: [2000|2500] Average Loss: 1.8221\n",
            "Epoch: [19/100], Batch steps: [2500|2500] Average Loss: 1.8289\n",
            "\n",
            "Epoch: [20/100], Batch steps: [500|2500] Average Loss: 1.8187\n",
            "Epoch: [20/100], Batch steps: [1000|2500] Average Loss: 1.8266\n",
            "Epoch: [20/100], Batch steps: [1500|2500] Average Loss: 1.8150\n",
            "Epoch: [20/100], Batch steps: [2000|2500] Average Loss: 1.8241\n",
            "Epoch: [20/100], Batch steps: [2500|2500] Average Loss: 1.8205\n",
            "\n",
            "Epoch: [21/100], Batch steps: [500|2500] Average Loss: 1.8162\n",
            "Epoch: [21/100], Batch steps: [1000|2500] Average Loss: 1.8112\n",
            "Epoch: [21/100], Batch steps: [1500|2500] Average Loss: 1.8221\n",
            "Epoch: [21/100], Batch steps: [2000|2500] Average Loss: 1.8194\n",
            "Epoch: [21/100], Batch steps: [2500|2500] Average Loss: 1.8191\n",
            "\n",
            "Epoch: [22/100], Batch steps: [500|2500] Average Loss: 1.8197\n",
            "Epoch: [22/100], Batch steps: [1000|2500] Average Loss: 1.8097\n",
            "Epoch: [22/100], Batch steps: [1500|2500] Average Loss: 1.8136\n",
            "Epoch: [22/100], Batch steps: [2000|2500] Average Loss: 1.8109\n",
            "Epoch: [22/100], Batch steps: [2500|2500] Average Loss: 1.8154\n",
            "\n",
            "Epoch: [23/100], Batch steps: [500|2500] Average Loss: 1.8089\n",
            "Epoch: [23/100], Batch steps: [1000|2500] Average Loss: 1.8034\n",
            "Epoch: [23/100], Batch steps: [1500|2500] Average Loss: 1.8094\n",
            "Epoch: [23/100], Batch steps: [2000|2500] Average Loss: 1.8068\n",
            "Epoch: [23/100], Batch steps: [2500|2500] Average Loss: 1.8148\n",
            "\n",
            "Epoch: [24/100], Batch steps: [500|2500] Average Loss: 1.7987\n",
            "Epoch: [24/100], Batch steps: [1000|2500] Average Loss: 1.8020\n",
            "Epoch: [24/100], Batch steps: [1500|2500] Average Loss: 1.8051\n",
            "Epoch: [24/100], Batch steps: [2000|2500] Average Loss: 1.8132\n",
            "Epoch: [24/100], Batch steps: [2500|2500] Average Loss: 1.8087\n",
            "\n",
            "Epoch: [25/100], Batch steps: [500|2500] Average Loss: 1.8013\n",
            "Epoch: [25/100], Batch steps: [1000|2500] Average Loss: 1.7955\n",
            "Epoch: [25/100], Batch steps: [1500|2500] Average Loss: 1.8074\n",
            "Epoch: [25/100], Batch steps: [2000|2500] Average Loss: 1.8027\n",
            "Epoch: [25/100], Batch steps: [2500|2500] Average Loss: 1.8011\n",
            "\n",
            "Epoch: [26/100], Batch steps: [500|2500] Average Loss: 1.7947\n",
            "Epoch: [26/100], Batch steps: [1000|2500] Average Loss: 1.8021\n",
            "Epoch: [26/100], Batch steps: [1500|2500] Average Loss: 1.7971\n",
            "Epoch: [26/100], Batch steps: [2000|2500] Average Loss: 1.7986\n",
            "Epoch: [26/100], Batch steps: [2500|2500] Average Loss: 1.7987\n",
            "\n",
            "Epoch: [27/100], Batch steps: [500|2500] Average Loss: 1.7932\n",
            "Epoch: [27/100], Batch steps: [1000|2500] Average Loss: 1.7985\n",
            "Epoch: [27/100], Batch steps: [1500|2500] Average Loss: 1.8006\n",
            "Epoch: [27/100], Batch steps: [2000|2500] Average Loss: 1.7870\n",
            "Epoch: [27/100], Batch steps: [2500|2500] Average Loss: 1.7970\n",
            "\n",
            "Epoch: [28/100], Batch steps: [500|2500] Average Loss: 1.7965\n",
            "Epoch: [28/100], Batch steps: [1000|2500] Average Loss: 1.7828\n",
            "Epoch: [28/100], Batch steps: [1500|2500] Average Loss: 1.7944\n",
            "Epoch: [28/100], Batch steps: [2000|2500] Average Loss: 1.7956\n",
            "Epoch: [28/100], Batch steps: [2500|2500] Average Loss: 1.7913\n",
            "\n",
            "Epoch: [29/100], Batch steps: [500|2500] Average Loss: 1.7911\n",
            "Epoch: [29/100], Batch steps: [1000|2500] Average Loss: 1.7855\n",
            "Epoch: [29/100], Batch steps: [1500|2500] Average Loss: 1.7828\n",
            "Epoch: [29/100], Batch steps: [2000|2500] Average Loss: 1.7916\n",
            "Epoch: [29/100], Batch steps: [2500|2500] Average Loss: 1.7886\n",
            "\n",
            "Epoch: [30/100], Batch steps: [500|2500] Average Loss: 1.7840\n",
            "Epoch: [30/100], Batch steps: [1000|2500] Average Loss: 1.7827\n",
            "Epoch: [30/100], Batch steps: [1500|2500] Average Loss: 1.7856\n",
            "Epoch: [30/100], Batch steps: [2000|2500] Average Loss: 1.7899\n",
            "Epoch: [30/100], Batch steps: [2500|2500] Average Loss: 1.7852\n",
            "\n",
            "Epoch: [31/100], Batch steps: [500|2500] Average Loss: 1.7765\n",
            "Epoch: [31/100], Batch steps: [1000|2500] Average Loss: 1.7886\n",
            "Epoch: [31/100], Batch steps: [1500|2500] Average Loss: 1.7813\n",
            "Epoch: [31/100], Batch steps: [2000|2500] Average Loss: 1.7904\n",
            "Epoch: [31/100], Batch steps: [2500|2500] Average Loss: 1.7748\n",
            "\n",
            "Epoch: [32/100], Batch steps: [500|2500] Average Loss: 1.7774\n",
            "Epoch: [32/100], Batch steps: [1000|2500] Average Loss: 1.7775\n",
            "Epoch: [32/100], Batch steps: [1500|2500] Average Loss: 1.7842\n",
            "Epoch: [32/100], Batch steps: [2000|2500] Average Loss: 1.7779\n",
            "Epoch: [32/100], Batch steps: [2500|2500] Average Loss: 1.7812\n",
            "\n",
            "Epoch: [33/100], Batch steps: [500|2500] Average Loss: 1.7710\n",
            "Epoch: [33/100], Batch steps: [1000|2500] Average Loss: 1.7827\n",
            "Epoch: [33/100], Batch steps: [1500|2500] Average Loss: 1.7845\n",
            "Epoch: [33/100], Batch steps: [2000|2500] Average Loss: 1.7729\n",
            "Epoch: [33/100], Batch steps: [2500|2500] Average Loss: 1.7791\n",
            "\n",
            "Epoch: [34/100], Batch steps: [500|2500] Average Loss: 1.7695\n",
            "Epoch: [34/100], Batch steps: [1000|2500] Average Loss: 1.7716\n",
            "Epoch: [34/100], Batch steps: [1500|2500] Average Loss: 1.7775\n",
            "Epoch: [34/100], Batch steps: [2000|2500] Average Loss: 1.7779\n",
            "Epoch: [34/100], Batch steps: [2500|2500] Average Loss: 1.7773\n",
            "\n",
            "Epoch: [35/100], Batch steps: [500|2500] Average Loss: 1.7703\n",
            "Epoch: [35/100], Batch steps: [1000|2500] Average Loss: 1.7625\n",
            "Epoch: [35/100], Batch steps: [1500|2500] Average Loss: 1.7760\n",
            "Epoch: [35/100], Batch steps: [2000|2500] Average Loss: 1.7739\n",
            "Epoch: [35/100], Batch steps: [2500|2500] Average Loss: 1.7720\n",
            "\n",
            "Epoch: [36/100], Batch steps: [500|2500] Average Loss: 1.7762\n",
            "Epoch: [36/100], Batch steps: [1000|2500] Average Loss: 1.7703\n",
            "Epoch: [36/100], Batch steps: [1500|2500] Average Loss: 1.7686\n",
            "Epoch: [36/100], Batch steps: [2000|2500] Average Loss: 1.7676\n",
            "Epoch: [36/100], Batch steps: [2500|2500] Average Loss: 1.7667\n",
            "\n",
            "Epoch: [37/100], Batch steps: [500|2500] Average Loss: 1.7716\n",
            "Epoch: [37/100], Batch steps: [1000|2500] Average Loss: 1.7677\n",
            "Epoch: [37/100], Batch steps: [1500|2500] Average Loss: 1.7655\n",
            "Epoch: [37/100], Batch steps: [2000|2500] Average Loss: 1.7663\n",
            "Epoch: [37/100], Batch steps: [2500|2500] Average Loss: 1.7662\n",
            "\n",
            "Epoch: [38/100], Batch steps: [500|2500] Average Loss: 1.7624\n",
            "Epoch: [38/100], Batch steps: [1000|2500] Average Loss: 1.7603\n",
            "Epoch: [38/100], Batch steps: [1500|2500] Average Loss: 1.7718\n",
            "Epoch: [38/100], Batch steps: [2000|2500] Average Loss: 1.7640\n",
            "Epoch: [38/100], Batch steps: [2500|2500] Average Loss: 1.7654\n",
            "\n",
            "Epoch: [39/100], Batch steps: [500|2500] Average Loss: 1.7598\n",
            "Epoch: [39/100], Batch steps: [1000|2500] Average Loss: 1.7639\n",
            "Epoch: [39/100], Batch steps: [1500|2500] Average Loss: 1.7595\n",
            "Epoch: [39/100], Batch steps: [2000|2500] Average Loss: 1.7588\n",
            "Epoch: [39/100], Batch steps: [2500|2500] Average Loss: 1.7740\n",
            "\n",
            "Epoch: [40/100], Batch steps: [500|2500] Average Loss: 1.7567\n",
            "Epoch: [40/100], Batch steps: [1000|2500] Average Loss: 1.7676\n",
            "Epoch: [40/100], Batch steps: [1500|2500] Average Loss: 1.7559\n",
            "Epoch: [40/100], Batch steps: [2000|2500] Average Loss: 1.7606\n",
            "Epoch: [40/100], Batch steps: [2500|2500] Average Loss: 1.7599\n",
            "\n",
            "Epoch: [41/100], Batch steps: [500|2500] Average Loss: 1.7678\n",
            "Epoch: [41/100], Batch steps: [1000|2500] Average Loss: 1.7585\n",
            "Epoch: [41/100], Batch steps: [1500|2500] Average Loss: 1.7571\n",
            "Epoch: [41/100], Batch steps: [2000|2500] Average Loss: 1.7548\n",
            "Epoch: [41/100], Batch steps: [2500|2500] Average Loss: 1.7558\n",
            "\n",
            "Epoch: [42/100], Batch steps: [500|2500] Average Loss: 1.7590\n",
            "Epoch: [42/100], Batch steps: [1000|2500] Average Loss: 1.7509\n",
            "Epoch: [42/100], Batch steps: [1500|2500] Average Loss: 1.7538\n",
            "Epoch: [42/100], Batch steps: [2000|2500] Average Loss: 1.7587\n",
            "Epoch: [42/100], Batch steps: [2500|2500] Average Loss: 1.7594\n",
            "\n",
            "Epoch: [43/100], Batch steps: [500|2500] Average Loss: 1.7507\n",
            "Epoch: [43/100], Batch steps: [1000|2500] Average Loss: 1.7495\n",
            "Epoch: [43/100], Batch steps: [1500|2500] Average Loss: 1.7540\n",
            "Epoch: [43/100], Batch steps: [2000|2500] Average Loss: 1.7549\n",
            "Epoch: [43/100], Batch steps: [2500|2500] Average Loss: 1.7593\n",
            "\n",
            "Epoch: [44/100], Batch steps: [500|2500] Average Loss: 1.7492\n",
            "Epoch: [44/100], Batch steps: [1000|2500] Average Loss: 1.7515\n",
            "Epoch: [44/100], Batch steps: [1500|2500] Average Loss: 1.7499\n",
            "Epoch: [44/100], Batch steps: [2000|2500] Average Loss: 1.7572\n",
            "Epoch: [44/100], Batch steps: [2500|2500] Average Loss: 1.7552\n",
            "\n",
            "Epoch: [45/100], Batch steps: [500|2500] Average Loss: 1.7549\n",
            "Epoch: [45/100], Batch steps: [1000|2500] Average Loss: 1.7466\n",
            "Epoch: [45/100], Batch steps: [1500|2500] Average Loss: 1.7466\n",
            "Epoch: [45/100], Batch steps: [2000|2500] Average Loss: 1.7509\n",
            "Epoch: [45/100], Batch steps: [2500|2500] Average Loss: 1.7542\n",
            "\n",
            "Epoch: [46/100], Batch steps: [500|2500] Average Loss: 1.7484\n",
            "Epoch: [46/100], Batch steps: [1000|2500] Average Loss: 1.7469\n",
            "Epoch: [46/100], Batch steps: [1500|2500] Average Loss: 1.7507\n",
            "Epoch: [46/100], Batch steps: [2000|2500] Average Loss: 1.7419\n",
            "Epoch: [46/100], Batch steps: [2500|2500] Average Loss: 1.7560\n",
            "\n",
            "Epoch: [47/100], Batch steps: [500|2500] Average Loss: 1.7452\n",
            "Epoch: [47/100], Batch steps: [1000|2500] Average Loss: 1.7517\n",
            "Epoch: [47/100], Batch steps: [1500|2500] Average Loss: 1.7479\n",
            "Epoch: [47/100], Batch steps: [2000|2500] Average Loss: 1.7452\n",
            "Epoch: [47/100], Batch steps: [2500|2500] Average Loss: 1.7475\n",
            "\n",
            "Epoch: [48/100], Batch steps: [500|2500] Average Loss: 1.7413\n",
            "Epoch: [48/100], Batch steps: [1000|2500] Average Loss: 1.7462\n",
            "Epoch: [48/100], Batch steps: [1500|2500] Average Loss: 1.7442\n",
            "Epoch: [48/100], Batch steps: [2000|2500] Average Loss: 1.7450\n",
            "Epoch: [48/100], Batch steps: [2500|2500] Average Loss: 1.7497\n",
            "\n",
            "Epoch: [49/100], Batch steps: [500|2500] Average Loss: 1.7348\n",
            "Epoch: [49/100], Batch steps: [1000|2500] Average Loss: 1.7493\n",
            "Epoch: [49/100], Batch steps: [1500|2500] Average Loss: 1.7414\n",
            "Epoch: [49/100], Batch steps: [2000|2500] Average Loss: 1.7414\n",
            "Epoch: [49/100], Batch steps: [2500|2500] Average Loss: 1.7490\n",
            "\n",
            "Epoch: [50/100], Batch steps: [500|2500] Average Loss: 1.7409\n",
            "Epoch: [50/100], Batch steps: [1000|2500] Average Loss: 1.7354\n",
            "Epoch: [50/100], Batch steps: [1500|2500] Average Loss: 1.7502\n",
            "Epoch: [50/100], Batch steps: [2000|2500] Average Loss: 1.7409\n",
            "Epoch: [50/100], Batch steps: [2500|2500] Average Loss: 1.7412\n",
            "\n",
            "Epoch: [51/100], Batch steps: [500|2500] Average Loss: 1.7358\n",
            "Epoch: [51/100], Batch steps: [1000|2500] Average Loss: 1.7410\n",
            "Epoch: [51/100], Batch steps: [1500|2500] Average Loss: 1.7378\n",
            "Epoch: [51/100], Batch steps: [2000|2500] Average Loss: 1.7459\n",
            "Epoch: [51/100], Batch steps: [2500|2500] Average Loss: 1.7343\n",
            "\n",
            "Epoch: [52/100], Batch steps: [500|2500] Average Loss: 1.7419\n",
            "Epoch: [52/100], Batch steps: [1000|2500] Average Loss: 1.7297\n",
            "Epoch: [52/100], Batch steps: [1500|2500] Average Loss: 1.7329\n",
            "Epoch: [52/100], Batch steps: [2000|2500] Average Loss: 1.7445\n",
            "Epoch: [52/100], Batch steps: [2500|2500] Average Loss: 1.7421\n",
            "\n",
            "Epoch: [53/100], Batch steps: [500|2500] Average Loss: 1.7385\n",
            "Epoch: [53/100], Batch steps: [1000|2500] Average Loss: 1.7404\n",
            "Epoch: [53/100], Batch steps: [1500|2500] Average Loss: 1.7351\n",
            "Epoch: [53/100], Batch steps: [2000|2500] Average Loss: 1.7324\n",
            "Epoch: [53/100], Batch steps: [2500|2500] Average Loss: 1.7347\n",
            "\n",
            "Epoch: [54/100], Batch steps: [500|2500] Average Loss: 1.7329\n",
            "Epoch: [54/100], Batch steps: [1000|2500] Average Loss: 1.7294\n",
            "Epoch: [54/100], Batch steps: [1500|2500] Average Loss: 1.7313\n",
            "Epoch: [54/100], Batch steps: [2000|2500] Average Loss: 1.7405\n",
            "Epoch: [54/100], Batch steps: [2500|2500] Average Loss: 1.7383\n",
            "\n",
            "Epoch: [55/100], Batch steps: [500|2500] Average Loss: 1.7295\n",
            "Epoch: [55/100], Batch steps: [1000|2500] Average Loss: 1.7331\n",
            "Epoch: [55/100], Batch steps: [1500|2500] Average Loss: 1.7308\n",
            "Epoch: [55/100], Batch steps: [2000|2500] Average Loss: 1.7306\n",
            "Epoch: [55/100], Batch steps: [2500|2500] Average Loss: 1.7398\n",
            "\n",
            "Epoch: [56/100], Batch steps: [500|2500] Average Loss: 1.7205\n",
            "Epoch: [56/100], Batch steps: [1000|2500] Average Loss: 1.7314\n",
            "Epoch: [56/100], Batch steps: [1500|2500] Average Loss: 1.7314\n",
            "Epoch: [56/100], Batch steps: [2000|2500] Average Loss: 1.7362\n",
            "Epoch: [56/100], Batch steps: [2500|2500] Average Loss: 1.7386\n",
            "\n",
            "Epoch: [57/100], Batch steps: [500|2500] Average Loss: 1.7254\n",
            "Epoch: [57/100], Batch steps: [1000|2500] Average Loss: 1.7255\n",
            "Epoch: [57/100], Batch steps: [1500|2500] Average Loss: 1.7354\n",
            "Epoch: [57/100], Batch steps: [2000|2500] Average Loss: 1.7308\n",
            "Epoch: [57/100], Batch steps: [2500|2500] Average Loss: 1.7387\n",
            "\n",
            "Epoch: [58/100], Batch steps: [500|2500] Average Loss: 1.7248\n",
            "Epoch: [58/100], Batch steps: [1000|2500] Average Loss: 1.7269\n",
            "Epoch: [58/100], Batch steps: [1500|2500] Average Loss: 1.7292\n",
            "Epoch: [58/100], Batch steps: [2000|2500] Average Loss: 1.7339\n",
            "Epoch: [58/100], Batch steps: [2500|2500] Average Loss: 1.7278\n",
            "\n",
            "Epoch: [59/100], Batch steps: [500|2500] Average Loss: 1.7267\n",
            "Epoch: [59/100], Batch steps: [1000|2500] Average Loss: 1.7314\n",
            "Epoch: [59/100], Batch steps: [1500|2500] Average Loss: 1.7275\n",
            "Epoch: [59/100], Batch steps: [2000|2500] Average Loss: 1.7277\n",
            "Epoch: [59/100], Batch steps: [2500|2500] Average Loss: 1.7265\n",
            "\n",
            "Epoch: [60/100], Batch steps: [500|2500] Average Loss: 1.7260\n",
            "Epoch: [60/100], Batch steps: [1000|2500] Average Loss: 1.7249\n",
            "Epoch: [60/100], Batch steps: [1500|2500] Average Loss: 1.7195\n",
            "Epoch: [60/100], Batch steps: [2000|2500] Average Loss: 1.7325\n",
            "Epoch: [60/100], Batch steps: [2500|2500] Average Loss: 1.7242\n",
            "\n",
            "Epoch: [61/100], Batch steps: [500|2500] Average Loss: 1.7199\n",
            "Epoch: [61/100], Batch steps: [1000|2500] Average Loss: 1.7227\n",
            "Epoch: [61/100], Batch steps: [1500|2500] Average Loss: 1.7339\n",
            "Epoch: [61/100], Batch steps: [2000|2500] Average Loss: 1.7205\n",
            "Epoch: [61/100], Batch steps: [2500|2500] Average Loss: 1.7238\n",
            "\n",
            "Epoch: [62/100], Batch steps: [500|2500] Average Loss: 1.7183\n",
            "Epoch: [62/100], Batch steps: [1000|2500] Average Loss: 1.7205\n",
            "Epoch: [62/100], Batch steps: [1500|2500] Average Loss: 1.7234\n",
            "Epoch: [62/100], Batch steps: [2000|2500] Average Loss: 1.7234\n",
            "Epoch: [62/100], Batch steps: [2500|2500] Average Loss: 1.7265\n",
            "\n",
            "Epoch: [63/100], Batch steps: [500|2500] Average Loss: 1.7188\n",
            "Epoch: [63/100], Batch steps: [1000|2500] Average Loss: 1.7247\n",
            "Epoch: [63/100], Batch steps: [1500|2500] Average Loss: 1.7225\n",
            "Epoch: [63/100], Batch steps: [2000|2500] Average Loss: 1.7180\n",
            "Epoch: [63/100], Batch steps: [2500|2500] Average Loss: 1.7261\n",
            "\n",
            "Epoch: [64/100], Batch steps: [500|2500] Average Loss: 1.7178\n",
            "Epoch: [64/100], Batch steps: [1000|2500] Average Loss: 1.7222\n",
            "Epoch: [64/100], Batch steps: [1500|2500] Average Loss: 1.7199\n",
            "Epoch: [64/100], Batch steps: [2000|2500] Average Loss: 1.7198\n",
            "Epoch: [64/100], Batch steps: [2500|2500] Average Loss: 1.7221\n",
            "\n",
            "Epoch: [65/100], Batch steps: [500|2500] Average Loss: 1.7207\n",
            "Epoch: [65/100], Batch steps: [1000|2500] Average Loss: 1.7186\n",
            "Epoch: [65/100], Batch steps: [1500|2500] Average Loss: 1.7186\n",
            "Epoch: [65/100], Batch steps: [2000|2500] Average Loss: 1.7185\n",
            "Epoch: [65/100], Batch steps: [2500|2500] Average Loss: 1.7213\n",
            "\n",
            "Epoch: [66/100], Batch steps: [500|2500] Average Loss: 1.7167\n",
            "Epoch: [66/100], Batch steps: [1000|2500] Average Loss: 1.7149\n",
            "Epoch: [66/100], Batch steps: [1500|2500] Average Loss: 1.7254\n",
            "Epoch: [66/100], Batch steps: [2000|2500] Average Loss: 1.7142\n",
            "Epoch: [66/100], Batch steps: [2500|2500] Average Loss: 1.7185\n",
            "\n",
            "Epoch: [67/100], Batch steps: [500|2500] Average Loss: 1.7156\n",
            "Epoch: [67/100], Batch steps: [1000|2500] Average Loss: 1.7141\n",
            "Epoch: [67/100], Batch steps: [1500|2500] Average Loss: 1.7188\n",
            "Epoch: [67/100], Batch steps: [2000|2500] Average Loss: 1.7183\n",
            "Epoch: [67/100], Batch steps: [2500|2500] Average Loss: 1.7237\n",
            "\n",
            "Epoch: [68/100], Batch steps: [500|2500] Average Loss: 1.7135\n",
            "Epoch: [68/100], Batch steps: [1000|2500] Average Loss: 1.7170\n",
            "Epoch: [68/100], Batch steps: [1500|2500] Average Loss: 1.7106\n",
            "Epoch: [68/100], Batch steps: [2000|2500] Average Loss: 1.7167\n",
            "Epoch: [68/100], Batch steps: [2500|2500] Average Loss: 1.7208\n",
            "\n",
            "Epoch: [69/100], Batch steps: [500|2500] Average Loss: 1.7047\n",
            "Epoch: [69/100], Batch steps: [1000|2500] Average Loss: 1.7163\n",
            "Epoch: [69/100], Batch steps: [1500|2500] Average Loss: 1.7093\n",
            "Epoch: [69/100], Batch steps: [2000|2500] Average Loss: 1.7231\n",
            "Epoch: [69/100], Batch steps: [2500|2500] Average Loss: 1.7217\n",
            "\n",
            "Epoch: [70/100], Batch steps: [500|2500] Average Loss: 1.7130\n",
            "Epoch: [70/100], Batch steps: [1000|2500] Average Loss: 1.7147\n",
            "Epoch: [70/100], Batch steps: [1500|2500] Average Loss: 1.7143\n",
            "Epoch: [70/100], Batch steps: [2000|2500] Average Loss: 1.7123\n",
            "Epoch: [70/100], Batch steps: [2500|2500] Average Loss: 1.7125\n",
            "\n",
            "Epoch: [71/100], Batch steps: [500|2500] Average Loss: 1.7060\n",
            "Epoch: [71/100], Batch steps: [1000|2500] Average Loss: 1.7096\n",
            "Epoch: [71/100], Batch steps: [1500|2500] Average Loss: 1.7193\n",
            "Epoch: [71/100], Batch steps: [2000|2500] Average Loss: 1.7141\n",
            "Epoch: [71/100], Batch steps: [2500|2500] Average Loss: 1.7106\n",
            "\n",
            "Epoch: [72/100], Batch steps: [500|2500] Average Loss: 1.7073\n",
            "Epoch: [72/100], Batch steps: [1000|2500] Average Loss: 1.7091\n",
            "Epoch: [72/100], Batch steps: [1500|2500] Average Loss: 1.7177\n",
            "Epoch: [72/100], Batch steps: [2000|2500] Average Loss: 1.7112\n",
            "Epoch: [72/100], Batch steps: [2500|2500] Average Loss: 1.7173\n",
            "\n",
            "Epoch: [73/100], Batch steps: [500|2500] Average Loss: 1.7158\n",
            "Epoch: [73/100], Batch steps: [1000|2500] Average Loss: 1.7088\n",
            "Epoch: [73/100], Batch steps: [1500|2500] Average Loss: 1.7061\n",
            "Epoch: [73/100], Batch steps: [2000|2500] Average Loss: 1.7156\n",
            "Epoch: [73/100], Batch steps: [2500|2500] Average Loss: 1.7077\n",
            "\n",
            "Epoch: [74/100], Batch steps: [500|2500] Average Loss: 1.7032\n",
            "Epoch: [74/100], Batch steps: [1000|2500] Average Loss: 1.7089\n",
            "Epoch: [74/100], Batch steps: [1500|2500] Average Loss: 1.7104\n",
            "Epoch: [74/100], Batch steps: [2000|2500] Average Loss: 1.7211\n",
            "Epoch: [74/100], Batch steps: [2500|2500] Average Loss: 1.7092\n",
            "\n",
            "Epoch: [75/100], Batch steps: [500|2500] Average Loss: 1.6992\n",
            "Epoch: [75/100], Batch steps: [1000|2500] Average Loss: 1.7110\n",
            "Epoch: [75/100], Batch steps: [1500|2500] Average Loss: 1.7116\n",
            "Epoch: [75/100], Batch steps: [2000|2500] Average Loss: 1.7094\n",
            "Epoch: [75/100], Batch steps: [2500|2500] Average Loss: 1.7149\n",
            "\n",
            "Epoch: [76/100], Batch steps: [500|2500] Average Loss: 1.7054\n",
            "Epoch: [76/100], Batch steps: [1000|2500] Average Loss: 1.6993\n",
            "Epoch: [76/100], Batch steps: [1500|2500] Average Loss: 1.7083\n",
            "Epoch: [76/100], Batch steps: [2000|2500] Average Loss: 1.7118\n",
            "Epoch: [76/100], Batch steps: [2500|2500] Average Loss: 1.7100\n",
            "\n",
            "Epoch: [77/100], Batch steps: [500|2500] Average Loss: 1.7051\n",
            "Epoch: [77/100], Batch steps: [1000|2500] Average Loss: 1.7131\n",
            "Epoch: [77/100], Batch steps: [1500|2500] Average Loss: 1.7072\n",
            "Epoch: [77/100], Batch steps: [2000|2500] Average Loss: 1.7050\n",
            "Epoch: [77/100], Batch steps: [2500|2500] Average Loss: 1.7076\n",
            "\n",
            "Epoch: [78/100], Batch steps: [500|2500] Average Loss: 1.7048\n",
            "Epoch: [78/100], Batch steps: [1000|2500] Average Loss: 1.6981\n",
            "Epoch: [78/100], Batch steps: [1500|2500] Average Loss: 1.7084\n",
            "Epoch: [78/100], Batch steps: [2000|2500] Average Loss: 1.7040\n",
            "Epoch: [78/100], Batch steps: [2500|2500] Average Loss: 1.7168\n",
            "\n",
            "Epoch: [79/100], Batch steps: [500|2500] Average Loss: 1.7054\n",
            "Epoch: [79/100], Batch steps: [1000|2500] Average Loss: 1.6966\n",
            "Epoch: [79/100], Batch steps: [1500|2500] Average Loss: 1.7054\n",
            "Epoch: [79/100], Batch steps: [2000|2500] Average Loss: 1.7146\n",
            "Epoch: [79/100], Batch steps: [2500|2500] Average Loss: 1.7041\n",
            "\n",
            "Epoch: [80/100], Batch steps: [500|2500] Average Loss: 1.6942\n",
            "Epoch: [80/100], Batch steps: [1000|2500] Average Loss: 1.7047\n",
            "Epoch: [80/100], Batch steps: [1500|2500] Average Loss: 1.7044\n",
            "Epoch: [80/100], Batch steps: [2000|2500] Average Loss: 1.7089\n",
            "Epoch: [80/100], Batch steps: [2500|2500] Average Loss: 1.7089\n",
            "\n",
            "Epoch: [81/100], Batch steps: [500|2500] Average Loss: 1.7024\n",
            "Epoch: [81/100], Batch steps: [1000|2500] Average Loss: 1.7075\n",
            "Epoch: [81/100], Batch steps: [1500|2500] Average Loss: 1.7015\n",
            "Epoch: [81/100], Batch steps: [2000|2500] Average Loss: 1.7035\n",
            "Epoch: [81/100], Batch steps: [2500|2500] Average Loss: 1.7021\n",
            "\n",
            "Epoch: [82/100], Batch steps: [500|2500] Average Loss: 1.7017\n",
            "Epoch: [82/100], Batch steps: [1000|2500] Average Loss: 1.6964\n",
            "Epoch: [82/100], Batch steps: [1500|2500] Average Loss: 1.6974\n",
            "Epoch: [82/100], Batch steps: [2000|2500] Average Loss: 1.7041\n",
            "Epoch: [82/100], Batch steps: [2500|2500] Average Loss: 1.7109\n",
            "\n",
            "Epoch: [83/100], Batch steps: [500|2500] Average Loss: 1.6942\n",
            "Epoch: [83/100], Batch steps: [1000|2500] Average Loss: 1.6973\n",
            "Epoch: [83/100], Batch steps: [1500|2500] Average Loss: 1.7042\n",
            "Epoch: [83/100], Batch steps: [2000|2500] Average Loss: 1.7022\n",
            "Epoch: [83/100], Batch steps: [2500|2500] Average Loss: 1.7085\n",
            "\n",
            "Epoch: [84/100], Batch steps: [500|2500] Average Loss: 1.7015\n",
            "Epoch: [84/100], Batch steps: [1000|2500] Average Loss: 1.7056\n",
            "Epoch: [84/100], Batch steps: [1500|2500] Average Loss: 1.6991\n",
            "Epoch: [84/100], Batch steps: [2000|2500] Average Loss: 1.7000\n",
            "Epoch: [84/100], Batch steps: [2500|2500] Average Loss: 1.6994\n",
            "\n",
            "Epoch: [85/100], Batch steps: [500|2500] Average Loss: 1.7012\n",
            "Epoch: [85/100], Batch steps: [1000|2500] Average Loss: 1.6976\n",
            "Epoch: [85/100], Batch steps: [1500|2500] Average Loss: 1.7026\n",
            "Epoch: [85/100], Batch steps: [2000|2500] Average Loss: 1.6981\n",
            "Epoch: [85/100], Batch steps: [2500|2500] Average Loss: 1.6999\n",
            "\n",
            "Epoch: [86/100], Batch steps: [500|2500] Average Loss: 1.6918\n",
            "Epoch: [86/100], Batch steps: [1000|2500] Average Loss: 1.6933\n",
            "Epoch: [86/100], Batch steps: [1500|2500] Average Loss: 1.7066\n",
            "Epoch: [86/100], Batch steps: [2000|2500] Average Loss: 1.7030\n",
            "Epoch: [86/100], Batch steps: [2500|2500] Average Loss: 1.7027\n",
            "\n",
            "Epoch: [87/100], Batch steps: [500|2500] Average Loss: 1.6889\n",
            "Epoch: [87/100], Batch steps: [1000|2500] Average Loss: 1.7059\n",
            "Epoch: [87/100], Batch steps: [1500|2500] Average Loss: 1.6958\n",
            "Epoch: [87/100], Batch steps: [2000|2500] Average Loss: 1.6963\n",
            "Epoch: [87/100], Batch steps: [2500|2500] Average Loss: 1.7081\n",
            "\n",
            "Epoch: [88/100], Batch steps: [500|2500] Average Loss: 1.6974\n",
            "Epoch: [88/100], Batch steps: [1000|2500] Average Loss: 1.6984\n",
            "Epoch: [88/100], Batch steps: [1500|2500] Average Loss: 1.6969\n",
            "Epoch: [88/100], Batch steps: [2000|2500] Average Loss: 1.6979\n",
            "Epoch: [88/100], Batch steps: [2500|2500] Average Loss: 1.6964\n",
            "\n",
            "Epoch: [89/100], Batch steps: [500|2500] Average Loss: 1.6905\n",
            "Epoch: [89/100], Batch steps: [1000|2500] Average Loss: 1.6991\n",
            "Epoch: [89/100], Batch steps: [1500|2500] Average Loss: 1.6959\n",
            "Epoch: [89/100], Batch steps: [2000|2500] Average Loss: 1.7010\n",
            "Epoch: [89/100], Batch steps: [2500|2500] Average Loss: 1.6973\n",
            "\n",
            "Epoch: [90/100], Batch steps: [500|2500] Average Loss: 1.6962\n",
            "Epoch: [90/100], Batch steps: [1000|2500] Average Loss: 1.6905\n",
            "Epoch: [90/100], Batch steps: [1500|2500] Average Loss: 1.6965\n",
            "Epoch: [90/100], Batch steps: [2000|2500] Average Loss: 1.6967\n",
            "Epoch: [90/100], Batch steps: [2500|2500] Average Loss: 1.7007\n",
            "\n",
            "Epoch: [91/100], Batch steps: [500|2500] Average Loss: 1.6888\n",
            "Epoch: [91/100], Batch steps: [1000|2500] Average Loss: 1.6974\n",
            "Epoch: [91/100], Batch steps: [1500|2500] Average Loss: 1.6939\n",
            "Epoch: [91/100], Batch steps: [2000|2500] Average Loss: 1.7016\n",
            "Epoch: [91/100], Batch steps: [2500|2500] Average Loss: 1.6922\n",
            "\n",
            "Epoch: [92/100], Batch steps: [500|2500] Average Loss: 1.6947\n",
            "Epoch: [92/100], Batch steps: [1000|2500] Average Loss: 1.6924\n",
            "Epoch: [92/100], Batch steps: [1500|2500] Average Loss: 1.6915\n",
            "Epoch: [92/100], Batch steps: [2000|2500] Average Loss: 1.6947\n",
            "Epoch: [92/100], Batch steps: [2500|2500] Average Loss: 1.6983\n",
            "\n",
            "Epoch: [93/100], Batch steps: [500|2500] Average Loss: 1.6927\n",
            "Epoch: [93/100], Batch steps: [1000|2500] Average Loss: 1.6893\n",
            "Epoch: [93/100], Batch steps: [1500|2500] Average Loss: 1.6930\n",
            "Epoch: [93/100], Batch steps: [2000|2500] Average Loss: 1.6980\n",
            "Epoch: [93/100], Batch steps: [2500|2500] Average Loss: 1.6943\n",
            "\n",
            "Epoch: [94/100], Batch steps: [500|2500] Average Loss: 1.6992\n",
            "Epoch: [94/100], Batch steps: [1000|2500] Average Loss: 1.6926\n",
            "Epoch: [94/100], Batch steps: [1500|2500] Average Loss: 1.6894\n",
            "Epoch: [94/100], Batch steps: [2000|2500] Average Loss: 1.6960\n",
            "Epoch: [94/100], Batch steps: [2500|2500] Average Loss: 1.6909\n",
            "\n",
            "Epoch: [95/100], Batch steps: [500|2500] Average Loss: 1.6891\n",
            "Epoch: [95/100], Batch steps: [1000|2500] Average Loss: 1.6909\n",
            "Epoch: [95/100], Batch steps: [1500|2500] Average Loss: 1.6902\n",
            "Epoch: [95/100], Batch steps: [2000|2500] Average Loss: 1.6980\n",
            "Epoch: [95/100], Batch steps: [2500|2500] Average Loss: 1.6942\n",
            "\n",
            "Epoch: [96/100], Batch steps: [500|2500] Average Loss: 1.6870\n",
            "Epoch: [96/100], Batch steps: [1000|2500] Average Loss: 1.6850\n",
            "Epoch: [96/100], Batch steps: [1500|2500] Average Loss: 1.6907\n",
            "Epoch: [96/100], Batch steps: [2000|2500] Average Loss: 1.7001\n",
            "Epoch: [96/100], Batch steps: [2500|2500] Average Loss: 1.6936\n",
            "\n",
            "Epoch: [97/100], Batch steps: [500|2500] Average Loss: 1.6874\n",
            "Epoch: [97/100], Batch steps: [1000|2500] Average Loss: 1.6939\n",
            "Epoch: [97/100], Batch steps: [1500|2500] Average Loss: 1.6894\n",
            "Epoch: [97/100], Batch steps: [2000|2500] Average Loss: 1.6934\n",
            "Epoch: [97/100], Batch steps: [2500|2500] Average Loss: 1.6954\n",
            "\n",
            "Epoch: [98/100], Batch steps: [500|2500] Average Loss: 1.6870\n",
            "Epoch: [98/100], Batch steps: [1000|2500] Average Loss: 1.6873\n",
            "Epoch: [98/100], Batch steps: [1500|2500] Average Loss: 1.6939\n",
            "Epoch: [98/100], Batch steps: [2000|2500] Average Loss: 1.6911\n",
            "Epoch: [98/100], Batch steps: [2500|2500] Average Loss: 1.6898\n",
            "\n",
            "Epoch: [99/100], Batch steps: [500|2500] Average Loss: 1.6876\n",
            "Epoch: [99/100], Batch steps: [1000|2500] Average Loss: 1.6946\n",
            "Epoch: [99/100], Batch steps: [1500|2500] Average Loss: 1.6920\n",
            "Epoch: [99/100], Batch steps: [2000|2500] Average Loss: 1.6873\n",
            "Epoch: [99/100], Batch steps: [2500|2500] Average Loss: 1.6887\n",
            "\n",
            "Epoch: [100/100], Batch steps: [500|2500] Average Loss: 1.6900\n",
            "Epoch: [100/100], Batch steps: [1000|2500] Average Loss: 1.6937\n",
            "Epoch: [100/100], Batch steps: [1500|2500] Average Loss: 1.6874\n",
            "Epoch: [100/100], Batch steps: [2000|2500] Average Loss: 1.6862\n",
            "Epoch: [100/100], Batch steps: [2500|2500] Average Loss: 1.6856\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dCNFzyjctO9l"
      },
      "source": [
        "# print the train loss"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wDcR08tISnLh"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 281
        },
        "id": "1itXlJVnT5dG",
        "outputId": "09d6d3ad-7e86-4228-86b7-3ce4488cc938"
      },
      "source": [
        "plt.plot(train_loss)\n",
        "plt.title(\"CIFAR-10 CNN loss\")\n",
        "plt.show()"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6NbFdpb6tDaq"
      },
      "source": [
        "# save the trained model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qEvIVLrVcbj4"
      },
      "source": [
        "torch.save(model, 'model.pth')"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3jNfFqPMtGeA"
      },
      "source": [
        "# load the test data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s5Au57Q2UDRU"
      },
      "source": [
        "test_data = torchvision.datasets.CIFAR10(root='./datasets',\n",
        "                                       train=False,\n",
        "                                       transform=transforms.ToTensor())\n",
        "test_loader = torch.utils.data.DataLoader(dataset=train_data,\n",
        "                                           batch_size=BATCH_SIZE,\n",
        "                                           shuffle=True)"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r6GBXutFtIic"
      },
      "source": [
        "# load the trained model and test"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gGv1pRMCbRhq",
        "outputId": "74f22f2e-ff05-4e03-d2df-b8c2fa41eb07"
      },
      "source": [
        "model = torch.load('model.pth')\n",
        "model.eval()\n",
        "acc = 0\n",
        "\n",
        "for image, label in test_loader:\n",
        "    image = image.to(device)\n",
        "    label = label.to(device)\n",
        "\n",
        "    _, preds = torch.max(model(image.data), 1)\n",
        "    for (pred, ans) in zip(preds, label):\n",
        "        if pred == ans:\n",
        "            acc += 1\n",
        "    acc = acc / len(preds)\n",
        "print(acc)"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:36: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.9397233428044665\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "In5w2xyfsu61"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}
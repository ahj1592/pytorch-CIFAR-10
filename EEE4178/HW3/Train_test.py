# -*- coding: utf-8 -*-
"""HW3_Train_Test.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1NR3MWyfUJLEhAwpZKnx8us1ODSjWWABg

# Download FashionMNIST data
"""

import torch
device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
print(device)

import torchvision
import torchvision.transforms as transforms

train_data = torchvision.datasets.FashionMNIST(root='./datasets',
                                        train=True,
                                        transform=transforms.ToTensor(),
                                        download=True)
test_data = torchvision.datasets.FashionMNIST(root='./datasets',
                                        train=False,
                                        transform=transforms.ToTensor(),
                                        download=True)

train_size = int(len(train_data) * 0.8)
valid_size = len(train_data) - train_size

train_data, valid_data = torch.utils.data.random_split(train_data, 
                                                       [train_size, valid_size])
print(len(train_data))
print(len(valid_data))
print(len(test_data))

BATCH_SIZE = 50

train_loader = torch.utils.data.DataLoader(dataset=train_data,
                                           batch_size=BATCH_SIZE,
                                           shuffle=True)

valid_loader = torch.utils.data.DataLoader(dataset=valid_data,
                                           batch_size=BATCH_SIZE,
                                           shuffle=True)

test_loader = torch.utils.data.DataLoader(dataset=test_data,
                                          batch_size=BATCH_SIZE,
                                          shuffle=False)



"""# Check FashionMNIST data"""

import matplotlib
import matplotlib.pyplot as plt
from matplotlib.pyplot import imshow

def image_show(tensor_image):
  image = tensor_image.reshape(tensor_image.size()[1], tensor_image.size()[2])    # width x height
  imshow(image, cmap='gray')

images, labels = next(iter(train_loader))
image1, label1 = images[0], labels[0]
image2, label2 = images[1], labels[1]

image1.shape

image_show(image1)
plt.title(label1)

import numpy as np

fig = plt.figure(figsize=(30,30))

tmp_images = images[:10]
tmp_labels = labels[:10]
for i in range(len(tmp_images)):
  plt.subplot(1,len(tmp_images), i+1)
  plt.imshow(tmp_images[i].detach().numpy().reshape(28, 28), cmap='gray')
  plt.title(f'Class: {tmp_labels[i]}')

tmp_images, tmp_labels = [], []
for class_id in range(10):
    for i, label in enumerate(labels):
        if class_id == label:
            tmp_images.append(images[i])
            tmp_labels.append(labels[i])
            break
fig, axes = plt.subplots(2, 5, figsize=(25, 10))
for i, ax in enumerate(axes.flat):
    ax.imshow(tmp_images[i].detach().numpy().reshape(28, 28), cmap='gray')
    ax.set(title=f'Class: {tmp_labels[i]}')

plt.subplot(2, 1, 1)

"""# Build RNN & GRU model"""

import torch.nn as nn
import torch.nn.functional as F

# Hyper parameters
sequence_length = 28
input_size = 28     # input data의 차원
hidden_size = 128   # hidden state의 차원
num_layers = 10     # RNN의 은닉층 레이어 개수
num_classes = 10

class RNN(nn.Module):
  def __init__(self, input_size, hidden_size, num_layers, num_classes):
    super(RNN, self).__init__()
    self.hidden_size = hidden_size
    self.num_layers = num_layers
    self.rnn = nn.RNN(input_size, hidden_size, num_layers, batch_first=True)
    self.fc = nn.Linear(hidden_size, num_classes)

  def forward(self, x):
    h0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(device) 
    h0 = h0.requires_grad_()

    out, hn  = self.rnn(x, h0.detach()) 
    out = self.fc(out[:, -1, :])

    return out

class GRU(nn.Module):
  def __init__(self, input_size, hidden_size, num_layers, num_classes):
    super(GRU, self).__init__()
    self.hidden_size = hidden_size
    self.num_layers = num_layers
    self.gru = nn.GRU(input_size, hidden_size, num_layers, batch_first=True)
    self.fc = nn.Linear(hidden_size, num_classes)

  def forward(self, x):
    h0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(device)
    
    out, _  = self.gru(x, h0)
    out = self.fc(out[:,-1,:])

    return out

"""# Train the model"""

def train(model, train_loader, optimizer, criterion, train_losses):
    model.train()
    steps = len(train_loader)
    epoch_loss, acc = 0, 0
    total_loss, cnt = 0, 0

    for i, (image, label) in enumerate(train_loader, 1):
        image = image.reshape(-1, sequence_length, input_size).to(device)
        label = label.to(device)

        output = model(image)
        loss = criterion(output, label)

        optimizer.zero_grad()
        loss.backward()
        optimizer.step()

        train_losses.append(loss.item())
        total_loss += loss.item()
        cnt += 1

        epoch_loss += loss.item()
        _, preds = torch.max(output.data, 1)
        acc += (preds == label).sum().item()

        if i % (steps / 5) == 0:
            avg_loss = total_loss / cnt
            print(f'Batch steps: [{i}|{steps}] Average Train Loss: {avg_loss:.4f}')
            total_loss, cnt = 0, 0

    # return avg_epoch_loss, accuracy
    avg_epoch_loss = epoch_loss / len(train_loader)
    pct = 100 * acc / len(train_loader.dataset)
    return avg_epoch_loss, pct

def evaluate(model, data_loader, criterion, losses):
    model.eval()
    epoch_loss, acc = 0, 0
    with torch.no_grad():
        for (image, label) in data_loader:
            image = image.reshape(-1, sequence_length, input_size).to(device)
            label = label.to(device)

            output = model(image)
            loss = criterion(output, label)

            _, pred = torch.max(output.data, 1)
            acc += (pred == label).sum().item()
            losses.append(loss.item())
            epoch_loss += loss.item()

    pct = 100 * acc / len(data_loader.dataset)
    return epoch_loss / len(data_loader.dataset), pct

"""# Train & Test RNN model"""

sequence_length = 28
input_size = 28
hidden_size = 128
num_layers = 2
num_classes = 10

rnn_model = RNN(input_size=input_size, 
                hidden_size=hidden_size, 
                num_layers=num_layers, 
                num_classes=num_classes).to(device)

learning_rate = 0.001

criterion = nn.CrossEntropyLoss()
optimizer = torch.optim.Adam(rnn_model.parameters(), lr=learning_rate)

EPOCHS = 30

best_epoch = 0
best_valid_loss = float('inf')

train_losses = []
valid_losses = []

# Train
print('Train step')
for epoch in range(1, EPOCHS + 1):
    print(f'epoch: {epoch}')
    train_loss, train_acc = train(rnn_model, train_loader, optimizer, criterion, train_losses)
    valid_loss, valid_acc = evaluate(rnn_model, valid_loader, criterion, valid_losses)
    print(f'Valid Loss: {valid_loss:.4f}, Valid Accuracy(%): {valid_acc:.2f}')
    
    if valid_loss < best_valid_loss:
        best_valid_loss = valid_loss
        best_epoch = epoch
        torch.save(rnn_model, f'rnn_20161608.pth')
    print()

# Test
print('Test step')
best_rnn_model = torch.load(f'rnn_20161608.pth')
test_losses = []
loss, acc = evaluate(best_rnn_model, test_loader, criterion, test_losses)
print(f'Test Accuracy: {acc:.2f}')

def show_losses(losses, model_type, loss_type):
    plt.plot(losses)
    plt.title(f"FashionMNIST-{model_type}-{loss_type} loss")
    plt.show()

show_losses(train_losses, 'RNN', 'train')
show_losses(valid_losses, 'RNN', 'valid')

"""# Train & Test GRU model"""

sequence_length = 28
input_size = 28
hidden_size = 128
num_layers = 4 
num_classes = 10

gru_model = GRU(input_size=input_size, 
                hidden_size=hidden_size, 
                num_layers=num_layers, 
                num_classes=num_classes).to(device)

learning_rate = 0.001

criterion = nn.CrossEntropyLoss()
optimizer = torch.optim.Adam(gru_model.parameters(), lr=learning_rate)


EPOCHS = 40

best_epoch = 0
best_valid_loss = float('inf')

train_losses = []
valid_losses = []

# Train
print('Train step')
for epoch in range(1, EPOCHS + 1):
    print(f'epoch: {epoch}')
    train_loss, train_acc = train(gru_model, train_loader, optimizer, criterion, train_losses)
    valid_loss, valid_acc = evaluate(gru_model, valid_loader, criterion, valid_losses)
    print(f'Valid Loss: {valid_loss:.4f}, Valid Accuracy(%): {valid_acc:.2f}')
    
    if valid_loss < best_valid_loss:
        best_valid_loss = valid_loss
        best_epoch = epoch
        torch.save(gru_model, f'gru_20161608.pth')
    print()

# Test
print('Test step')
best_gru_model = torch.load(f'gru_20161608.pth')
test_losses = []
loss, acc = evaluate(best_gru_model, test_loader, criterion, test_losses)
print(f'Test Accuracy: {acc:.2f}')

show_losses(train_losses, 'GRU', 'train')
show_losses(valid_losses, 'GRU', 'valid')

